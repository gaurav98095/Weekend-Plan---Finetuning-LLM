{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb2a0e3",
   "metadata": {},
   "source": [
    "# Direct Preference Optimization (DPO) Fine-tuning Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e41cbf1",
   "metadata": {},
   "source": [
    "### 1. Setup and Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731866b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q trl transformers datasets accelerate peft bitsandbytes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6e6dee",
   "metadata": {},
   "source": [
    "#### 2. Load Dataset (sample from Hugging Face or custom dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31c2ff77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train size: 11573\n",
      "Test size: 1286\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_dataset = load_dataset(\"Intel/orca_dpo_pairs\")\n",
    "train_test_split = raw_dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "dataset = {\n",
    "    \"train\": train_test_split[\"train\"],\n",
    "    \"test\": train_test_split[\"test\"]\n",
    "}\n",
    "\n",
    "print(\"\\nTrain size:\", len(dataset[\"train\"]))\n",
    "print(\"Test size:\", len(dataset[\"test\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec58176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Record: {'system': 'You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.', 'question': 'Alex fell off their skateboard and into the ditch.  Given the question \"What will Alex want to do next?\", is \"go to a doctor\" a valid answer?\\nPick your answer from:\\n(A). Yes\\n(B). No\\nAnswer:', 'chosen': '(A). Yes\\n\\nStep 1: Understand the situation - Alex fell off their skateboard and into the ditch.\\n\\nStep 2: Consider possible outcomes - Alex might be injured or in pain after the fall.\\n\\nStep 3: Determine the user\\'s question - The user wants to know if \"go to a doctor\" is a valid answer for what Alex might want to do next.\\n\\nStep 4: Evaluate the answer options - We have two options, (A) Yes or (B) No.\\n\\nStep 5: Justify selection - Since falling into a ditch after a skateboarding accident can potentially result in injuries, it is reasonable to consider that Alex might want to go to a doctor to get checked out and address any injuries or pain they might have.\\n\\nThus, my answer is (A) Yes, \"go to a doctor\" is a valid answer for what Alex might want to do next.', 'rejected': ' Sure, I\\'d be happy to help!\\n\\nGiven the scenario that Alex fell off their skateboard and into a ditch, it\\'s likely that they may have sustained some injuries. In this case, it would not be advisable for Alex to go to a doctor immediately.\\n\\nHere are the steps I would take to determine if \"go to a doctor\" is a valid answer:\\n\\nStep 1: Consider the severity of the injuries.\\n\\nBased on the information provided, we don\\'t know the extent of Alex\\'s injuries. If they have sustained serious injuries such as a head injury, broken bones, or internal bleeding, they should seek medical attention immediately. In this case, \"go to a doctor\" would not be a valid answer.\\n\\nStep 2: Consider Alex\\'s current location and condition.\\n\\nIf Alex is in a remote location or is unable to move due to their injuries, it may not be possible for them to go to a doctor. In this case, it would be more appropriate to call for emergency medical services or wait for someone to come and assist them.\\n\\nStep 3: Consider Alex\\'s preferences and priorities.\\n\\nIt\\'s possible that Alex may prioritize getting medical attention as soon as possible, but it\\'s also possible that they may be more concerned with getting back to their skateboard and continuing their activity. If Alex is in a remote location and is unable to move, it may be more appropriate to call for emergency medical services or wait for someone to come and assist them.\\n\\nBased on these steps, it is not a valid answer to say that Alex should go to a doctor next. Instead, it would be more appropriate to call for emergency medical services or wait for someone to come and assist them.\\n\\nTherefore, my answer is (B). No.'}\n"
     ]
    }
   ],
   "source": [
    "# Sample format\n",
    "print(\"\\nSample Record:\", dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db61e7d",
   "metadata": {},
   "source": [
    "### 3. Load Base Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60977555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de74fd699f86476296df6984f31a9857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22513c8c20764a7da5b1ab711294f06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d85e385d463412cbccc9ed0a0fe0bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4225970394f4a05924584df2d45eaf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fde7567d937458d813cf963bbb68600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ac33af073940708285320ae577f1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecee44ea57064371a51d514af1a719ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"gpt2\"  # You can replace with any other causal LM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46266df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad token fix\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de5039a",
   "metadata": {},
   "source": [
    "### 4. Prepare TrainingArguments and DPOConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cb6b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from trl import DPOConfig\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./dpo-output\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    logging_steps=10,\n",
    "    learning_rate=5e-6,\n",
    "    warmup_steps=50,\n",
    "    num_train_epochs=1,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28a60cfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Your setup doesn't support bf16/gpu.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dpo_config = \u001b[43mDPOConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_prompt_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# log_with=None,\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:168\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, hub_revision, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, liger_kernel_config, eval_use_gather_object, average_tokens_across_devices, model_init_kwargs, ref_model_init_kwargs, model_adapter_name, ref_adapter_name, force_use_ref_model, disable_dropout, use_logits_to_keep, dataset_num_proc, padding_value, label_pad_token_id, max_prompt_length, max_completion_length, max_length, truncation_mode, padding_free, precompute_ref_log_probs, precompute_ref_batch_size, tools, loss_type, use_liger_loss, base_model_attribute_name, beta, f_divergence_type, f_alpha_divergence_coef, reference_free, label_smoothing, use_weighting, rpo_alpha, ld_alpha, discopop_tau, loss_weights, sync_ref_model, ref_model_mixup_alpha, ref_model_sync_steps, generate_during_eval)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.transformerlab/envs/transformerlab/lib/python3.11/site-packages/trl/trainer/dpo_config.py:461\u001b[39m, in \u001b[36mDPOConfig.__post_init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.loss_weights) != \u001b[38;5;28mlen\u001b[39m(loss_types):\n\u001b[32m    457\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    458\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLength of loss_weights list (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.loss_weights\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) must match number of loss types \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    459\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    460\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__post_init__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.transformerlab/envs/transformerlab/lib/python3.11/site-packages/transformers/training_args.py:1731\u001b[39m, in \u001b[36mTrainingArguments.__post_init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1729\u001b[39m                     error_message += \u001b[33m\"\u001b[39m\u001b[33m You need Ampere+ GPU with cuda>=11.0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1730\u001b[39m                 \u001b[38;5;66;03m# gpu\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1731\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_message)\n\u001b[32m   1733\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fp16 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bf16:\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAt most one of fp16 and bf16 can be True, but not both\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Your setup doesn't support bf16/gpu."
     ]
    }
   ],
   "source": [
    "dpo_config = DPOConfig(\n",
    "    beta=0.1,\n",
    "    max_prompt_length=512,\n",
    "    max_length=1024,\n",
    "    # log_with=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb7764a",
   "metadata": {},
   "source": [
    "### 5. Load DPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8669645",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dpo_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtrl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DPOTrainer\n\u001b[32m      3\u001b[39m trainer = DPOTrainer(\n\u001b[32m      4\u001b[39m     model=model,\n\u001b[32m      5\u001b[39m     ref_model=\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# If None, a frozen copy of the model will be used internally\u001b[39;00m\n\u001b[32m      6\u001b[39m     args=training_args,\n\u001b[32m      7\u001b[39m     tokenizer=tokenizer,\n\u001b[32m      8\u001b[39m     train_dataset=dataset[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      9\u001b[39m     eval_dataset=dataset[\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     dpo_config=\u001b[43mdpo_config\u001b[49m,\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'dpo_config' is not defined"
     ]
    }
   ],
   "source": [
    "from trl import DPOTrainer\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=None,  # If None, a frozen copy of the model will be used internally\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    dpo_config=dpo_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f7aa35",
   "metadata": {},
   "source": [
    "### 6. Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7299e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a87f67c",
   "metadata": {},
   "source": [
    "### 7. Save & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e72eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./dpo-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c32332",
   "metadata": {},
   "source": [
    "### 8. Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293dafc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Why is the sky blue?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "print(\"\\nGenerated Response:\\n\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bc91f7",
   "metadata": {},
   "source": [
    "### 9. Push to Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751bfc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(\"your-username/dpo-finetuned-model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
